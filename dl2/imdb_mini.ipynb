{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Language Model\n",
    "\n",
    "Key papers:\n",
    "\n",
    "'Learned in Translation: Contextualized Word Vectors' McCann et al. 2017\n",
    "\n",
    "'Regularizing and Optimizing LSTM Language Models', Merity et al. (2017)\n",
    "\n",
    "'A disciplined approach to neural network hyper-parameters: Part 1 -- learning rate, batch size, momentum, and weight decay', Smith (2018)\n",
    "\n",
    "Here we are testing on subset of imdb data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "import html\n",
    "import sys\n",
    "from subprocess import call\n",
    "\n",
    "import torch\n",
    "\n",
    "from fastai.text import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active CUDA Device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "print('Active CUDA Device: GPU', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS = 'xbos'    #beginning of sentence tag, useful for model to know this\n",
    "FLD = 'xfld'    #data field tag\n",
    "\n",
    "PATH=Path('..')/'data/imdb/aclImdb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test', 'imdbEr.txt', 'models', 'imdb.vocab', 'README', 'train', 'tmp']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classifier\n",
    "CLAS_PATH=Path('..')/'data/imdb/imdb_clas'\n",
    "CLAS_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "#Language Model\n",
    "LM_PATH=Path('..')/'data/imdb/imdb_lm'\n",
    "LM_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unsup for unlabelled\n",
    "CLASSES = ['neg', 'pos', 'unsup']\n",
    "\n",
    "def get_texts(path):\n",
    "    texts,labels = [],[]\n",
    "    for idx,label in enumerate(CLASSES):\n",
    "        #The glob module finds all the pathnames matching a specified pattern according to the rules used by the Unix shell\n",
    "        for fname in (path/label).glob('*.*'):\n",
    "            #eg ../data/imdb/aclImdb/train/neg/1696_1.txt\n",
    "            texts.append(fname.open('r').read())\n",
    "            labels.append(idx)\n",
    "    return np.array(texts), np.array(labels)\n",
    "\n",
    "trn_texts, trn_labels = get_texts(PATH/'train')\n",
    "val_texts, val_labels = get_texts(PATH/'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(trn_texts): 75000, len(val_texts): 25000\n"
     ]
    }
   ],
   "source": [
    "print(f'len(trn_texts): {len(trn_texts)}, len(val_texts): {len(val_texts)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clip data - identifying clipped data with '_mini' postfix\n",
    "trn_texts = trn_texts[:1500]\n",
    "trn_labels = trn_labels[:1500]\n",
    "val_texts = val_texts[:500]\n",
    "val_labels = val_labels[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['labels', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make randomness reproducible\n",
    "np.random.seed(42)\n",
    "#randomly shuffle this list\n",
    "trn_idx = np.random.permutation(len(trn_texts))\n",
    "val_idx = np.random.permutation(len(val_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create our randomly sorted training and validation lists-generally a good idea to do this\n",
    "trn_texts = trn_texts[trn_idx]\n",
    "val_texts = val_texts[val_idx]\n",
    "\n",
    "trn_labels = trn_labels[trn_idx]\n",
    "val_labels = val_labels[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn = pd.DataFrame({'text':trn_texts, 'labels':trn_labels}, columns=col_names)\n",
    "df_val = pd.DataFrame({'text':val_texts, 'labels':val_labels}, columns=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for training data, remove unsupervised\n",
    "df_trn[df_trn['labels']!=2].to_csv(CLAS_PATH/'train_mini.csv',header=False, index=False)\n",
    "df_val.to_csv(CLAS_PATH/'test_mini.csv', header=False, index=False)\n",
    "\n",
    "#write the classes to a file ie neg pos unsup\n",
    "(CLAS_PATH/'classes_mini.txt').open('w').writelines(f'{o}/n' for o in CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use more data for training than the given split\n",
    "trn_texts,val_texts = sklearn.model_selection.train_test_split(np.concatenate([trn_texts, val_texts]), test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800, 200)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_texts), len(val_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise classifications to zero\n",
    "df_trn = pd.DataFrame({'text':trn_texts, 'labels':[0]*len(trn_texts)}, columns=col_names)\n",
    "df_val = pd.DataFrame({'text':val_texts, 'labels':[0]*len(val_texts)}, columns=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn.to_csv(LM_PATH/'train_mini.csv', header=False, index=False)\n",
    "df_val.to_csv(LM_PATH/'test_mini.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Model Tokens\n",
    "\n",
    "Turn text into a a list of tokens using Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this makes pandas more efficient-when passed in to pandas, returns an iterator to iterate through chunks, then loop through these chinks of the dataframe\n",
    "CHUNKSIZE = 24000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile a regular expression pattern, returning a pattern object\n",
    "re1 = re.compile(r'  +')\n",
    "\n",
    "#this may not catch all badly formatted text, may need to add to/modify for other input datasets\n",
    "def fixup(text_str):\n",
    "    text_str = text_str.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>','u_n').replace(' @.@ ','.').replace(\n",
    "        ' @-@ ','-').replace('\\\\', ' \\\\ ')\n",
    "    return re1.sub(' ', html.unescape(text_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max thread count: 16\n"
     ]
    }
   ],
   "source": [
    "print(f'max thread count: {len(os.sched_getaffinity(0))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_texts(df, n_lbls=1):\n",
    "    #.iloc[<row_selection>,<col_selction>] here default is column 0 only\n",
    "    labels = df.iloc[:,range(n_lbls)].values.astype(np.int64)\n",
    "    texts = f'\\n{BOS} {FLD} 1 '+ df[n_lbls].astype(str)\n",
    "    for i in range(n_lbls+1, len(df.columns)):\n",
    "        texts += f' {FLD} {i-n_lbls} ' + df[i].astype(str)\n",
    "    texts = texts.apply(fixup).values.astype(str)\n",
    "    #type(texts): <class 'pandas.core.series.Series'>\n",
    "    #uses ProcessPoolExcutor with 1/2 of the cpu's, pass in a series to tokenize\n",
    "    start = timer()\n",
    "    #significant speed up gained through multi processing\n",
    "    tok = Tokenizer().proc_all_mp(partition_by_cores(texts))\n",
    "    end = timer()\n",
    "    print(f'elapsed: {end - start}')\n",
    "    return tok, list(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all(tf_reader, n_lbls):\n",
    "    #iterate over the TextFileReader object in chunks\n",
    "    tok, labels = [], []\n",
    "    for i, r in enumerate(tf_reader):\n",
    "        print(i)\n",
    "        tok_, labels_ = get_texts(r, n_lbls)\n",
    "        tok += tok_\n",
    "        labels += labels_\n",
    "    return tok, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(df_trn): <class 'pandas.io.parsers.TextFileReader'>\n"
     ]
    }
   ],
   "source": [
    "df_trn = pd.read_csv(LM_PATH/'train_mini.csv', header=None, chunksize=CHUNKSIZE)\n",
    "df_val = pd.read_csv(LM_PATH/'test_mini.csv', header=None, chunksize=CHUNKSIZE)\n",
    "#note is not a dataframe\n",
    "print(f'type(df_trn): {type(df_trn)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "elapsed: 3.4538926270001866\n",
      "0\n",
      "elapsed: 2.6493548379999083\n"
     ]
    }
   ],
   "source": [
    "tok_trn, trn_labels = get_all(df_trn, 1)\n",
    "tok_val, val_labels = get_all(df_val, 1)\n",
    "#note smaller output than full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "(LM_PATH/'tmp').mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n-xbos-xfld-1-first-thing-i-noticed-in-this-movie-of-course-,-was-the-unnecessary-amount-of-nudity-.-it-'s-not-oozing-nudity-or-anything-,-but-a-lot-that-was-not-needed-.-annik-borel-plays-a-disturbed-woman-believing-her-families-ghost-stories-that-her-ancestor-who-eerily-resembles-her-was-a-werewolf-,-and-believes-their-fate-are-destined-to-be-the-same-.-which-actually-i-found-quite-interesting-.-the-original-wolf-man-was-intended-to-be-a-completely-psychological-movie-,-but-universal-threw-in-the-actual-wolf-man-you-were-never-supposed-to-see-for-n-extra-buck-or-two-.-i-find-this-concept-of-someone-not-really-being-a-werewolf-interesting-.-unfortunately-this-is-not-the-film-i-was-searching-for-.-\\n\\n-instead-we-know-she-s-not-a-werewolf-from-the-beginning-,-so-there-'s-no-thrill-or-twist-,-also-they-attempt-to-make-the-film-seem-like-a-this-really-happened-scenario-.-they-fail-there-too-adding-one-or-two-parts-of-the-film-referring-to-this-being-reality-.-at-first-i-was-excited-upon-reading-the-description-of-the-film-.-but-i-slowly-realized-it-was-a-cover-just-so-they-could-expose-the-main-characters-breasts-as-often-as-possible-.-\\n\\n-annik-borel-is-either-a-decent-actor-playing-a-great-psychotic-role-,-or-a-really-bad-actor-playing-a-psychotic-role-.-since-the-character-danniele-has-no-brains-and-is-just-a-nut-who-runs-around-insane-and-snarling-and-snapping-like-a-wolf-,-it-takes-little-skill-to-play-.-she-has-moments-were-her-performance-breaks-through-for-a-creepy-moment-but-is-quickly-ruined-by-the-poor-camera-work-and-light-.-the-idea-is-great-,-but-hideously-executed-throughout-the-film-.-3-/-10\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first 100 chars example of data - t_up - indicates token is uppercase\n",
    "'-'.join(tok_trn[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(LM_PATH/'tmp'/'tok_trn_mini.npy', tok_trn)\n",
    "np.save(LM_PATH/'tmp'/'tok_val_mini.npy', tok_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_trn = np.load(LM_PATH/'tmp'/'tok_trn_mini.npy')\n",
    "tok_val = np.load(LM_PATH/'tmp'/'tok_val_mini.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 23957),\n",
       " ('.', 20425),\n",
       " (',', 19109),\n",
       " ('a', 11727),\n",
       " ('and', 10781),\n",
       " ('to', 10056),\n",
       " ('of', 9994),\n",
       " ('is', 7567),\n",
       " ('it', 7040),\n",
       " ('i', 6753),\n",
       " ('in', 6472),\n",
       " ('this', 5762),\n",
       " ('that', 5416),\n",
       " ('\"', 5168),\n",
       " (\"'s\", 4288),\n",
       " ('was', 4010),\n",
       " ('-', 3806),\n",
       " ('\\n\\n', 3776),\n",
       " ('movie', 3450),\n",
       " ('for', 3142),\n",
       " ('but', 3093),\n",
       " ('as', 3061),\n",
       " ('with', 3060),\n",
       " (\"n't\", 2829),\n",
       " ('film', 2800)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = Counter(p for o in tok_trn for p in o)\n",
    "freq.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limit as over this code gets 'clunky'\n",
    "#also for classification using >60k doesnt help anyway\n",
    "MAX_VOCAB = 60000\n",
    "MIN_FREQ = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of words, create index for this list\n",
    "\n",
    "itos: index to string\n",
    "stoi: string to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#index those tokens that appear more than 2x\n",
    "itos = [o for o,c in freq.most_common(MAX_VOCAB) if c>MIN_FREQ]\n",
    "itos.insert(0, '_pad_')\n",
    "#use if not in vocab\n",
    "itos.insert(0, '_unk_')\n",
    "itos[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9574"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#default to 0 if not in dict\n",
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n",
    "len(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#index each token for each review. Call for every word, for every sentence\n",
    "trn_lm = np.array([[stoi[o] for o in p] for p in tok_trn])\n",
    "val_lm = np.array([[stoi[o] for o in p] for p in tok_val])\n",
    "trn_lm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(LM_PATH/'tmp'/'trn_ids_mini.npy', trn_lm)\n",
    "np.save(LM_PATH/'tmp'/'val_ids_mini.npy', val_lm)\n",
    "pickle.dump(itos, open(LM_PATH/'tmp'/'itos_mini.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_lm = np.load(LM_PATH/'tmp'/'trn_ids_mini.npy')\n",
    "val_lm = np.load(LM_PATH/'tmp'/'val_ids_mini.npy')\n",
    "itos = pickle.load(open(LM_PATH/'tmp'/'itos_mini.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9574, 1800)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE = len(itos)\n",
    "VOCAB_SIZE, len(trn_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wikitext103 Conversion\n",
    "\n",
    "42:00\n",
    "\n",
    "Instead of pretraining on Imagenet, for NLP we can pretrain on a large subset of Wikipedia\n",
    "\n",
    "If pre-train classifier by first creating a language model then fine tune that as a classifier-helpful in L4 2017\n",
    "\n",
    "IMDB not that different to english docs - train a good @ English LM then fine tune.\n",
    "\n",
    "S. Merity created WikiText-103 contains all articles extracted from Wikipedia (ignoring smaller atricles):\n",
    "\n",
    "https://www.salesforce.com/products/einstein/ai-research/the-wikitext-dependency-language-modeling-dataset/\n",
    "\n",
    "JH trained this Language Model - start with these weights.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! wget -nH -r -np http://files.fast.ai/models/wt103/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our model needs to have exactly the same embedding size, number of hidden layers and number of layers as per Jeremy's wikitext103 LM\n",
    "EMBEDDING_SIZE = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_PATH = PATH/'models'/'wt103'\n",
    "PRE_LM_PATH = PRE_PATH/'fwd_wt103.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.load uses Python's unpickling facilities but treats storages, which underlie tensors, specially\n",
    "wgts = torch.load(PRE_LM_PATH, map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_wgts = to_np(wgts['0.encoder.weight'])\n",
    "row_m = enc_wgts.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eg row_m: array([-0.0183 , -0.13826,  0.01438, -0.01285,  0.00407,  0.01944,  0.01149, -0.13282, -0.02295, ... ], dtype=float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to map our itos to itos for wikitext, which is easy as we have the itos for wikitext103\n",
    "itos_wiki = pickle.load((PRE_PATH/'itos_wt103.pkl').open('rb'))\n",
    "#-1 means not in wikitext dictionary\n",
    "stoi_wiki = collections.defaultdict(lambda:-1, {v:k for k,v in enumerate(itos_wiki)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an empty embedding matrix\n",
    "new_wgts = np.zeros((VOCAB_SIZE, EMBEDDING_SIZE), dtype=np.float32)\n",
    "#go through every work in imdb vocab\n",
    "for i, w in enumerate(itos):\n",
    "    #look it up in wiki vocab\n",
    "    r = stoi_wiki[w]\n",
    "    #use mean if our string doesnt exist in wiki (-1 means not in wikitext dict)\n",
    "    new_wgts[i] = enc_wgts[r] if r>=0 else row_m\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#T: convert to torch tensor and put on gpu. Replace our weights\n",
    "wgts['0.encoder.weight'] = T(new_wgts)\n",
    "wgts['0.encoder_with_dropout.embed.weight'] = T(np.copy(new_wgts))\n",
    "#decoder (turns final prediction back into a word) uses same weights\n",
    "wgts['1.decoder.weight'] = T(np.copy(new_wgts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Model\n",
    "\n",
    "Word2Vec is a single embedding matrix - each word has a vector and thats it.\n",
    "\n",
    "A single layer (input layer) form a pre-trained linear model - pre-trained on a co-ocurrence matrix. No reason to beleive it has learnt anything about the English languguage nor do we expect it to have any great capabilities.\n",
    "\n",
    "This language model had a 400 dimensional embedding matrix, 3 hidden layers with 1150 activations per layer + reg - state of the art AWD LSTM.\n",
    "\n",
    "Single layer of linear model vs 3 layer RNN - very different capabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of hidden activation per LSTM layer\n",
    "n_hid= 1150\n",
    "#number of LSTM layers to use in the architecture\n",
    "n_layers = 3\n",
    "wd=1e-7\n",
    "#grab 70 at a time\n",
    "bptt=70\n",
    "bs=52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#betas (Tuple[float, float], optional): coefficients used for computing running averages of gradient and its square (default: (0.9, 0.999))\n",
    "#for nlp better to use the defaults below\n",
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate all our docs together\n",
    "t = len(np.concatenate(trn_lm))\n",
    "t, t//52"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our Language Model we concatenate all docs, will be continually trying to predict: what is the next word\n",
    "\n",
    "(The 3 lines below are the same code Jeremy also used to train the wikitext103 model from scratch)\n",
    "\n",
    "see fastai.model.fit function - where everything ends up eventually\n",
    "-goes through each epoch, creates an iterator form the dataloader\n",
    "\n",
    "    for epoch in tnrange(epochs, desc='Epoch'):\n",
    "        stepper.reset(True)\n",
    "        t = tqdm(iter(data.trn_dl), leave=False, total=num_batch)\n",
    "        \n",
    "-then does a for loop through it\n",
    "\n",
    "        for (*x,y) in t:\n",
    "        \n",
    "-dataloader just needs to return tuples (ind and dep var) for minibatches\n",
    "\n",
    "We start by initializing the LanguageModelLoader with a big list of numbers (all docs concatenated together).\n",
    "Then we batchify this - break total data into bs pieces ie here 64 pieces.\n",
    "\n",
    "ie data = data.reshape(self.bs, -1).T \n",
    "will thus have 64 columns and total_dala/64 rows\n",
    "\n",
    "as iterate through we grab a sequnce of c. 70 words and try to predict the next one word\n",
    "ie as below i to i+70 rows and try to predict that plus one\n",
    "\n",
    "    get_batch()\n",
    "        ...\n",
    "        return source[i:i+seq_len], source[i+1:i+1+seq_len].view(-1)\n",
    "        \n",
    "*1:05 - key ideas here, review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#when we iterate over LanguageModelLoader, the sequence length is changed with a normal distribution and significantly changed 5% of time\n",
    "#on first iteration: seq_len = bptt+5*5 ie 95 here\n",
    "#subseqently: seq_len = max(5, int(np.random.normal(bptt, 5))) where 5% of time the mean bptt=bptt/2\n",
    "trn_dl = LanguageModelLoader(np.concatenate(trn_lm), bs, bptt)\n",
    "val_dl = LanguageModelLoader(np.concatenate(val_lm), bs, bptt)\n",
    "\n",
    "#LanguageModelData returns a RNN_Learner with SequentialRNN model\n",
    "#(The SequentialRNN layer is the native torch's Sequential wrapper that puts the RNN_Encoder and LinearDecoder layers sequentially in the model.)\n",
    "model_data = LanguageModelData(PATH, pad_idx=1, nt=VOCAB_SIZE, trn_dl=trn_dl, val_dl=val_dl, bs=bs, bptt=bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropouts - through experimentation these work well.\n",
    "#less data need more dropout - good ratios, just tune the multiplier (if overfitting increase the multiplier)\n",
    "drops = np.array([0.25, 0.1, 0.2, 0.02, 0.15])*0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have a model data object we gan grab the model - which will give us a learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropout: dropout to apply to the activations going from one LSTM layer to another\n",
    "#dropouti (float): dropout to apply to the input layer.\n",
    "#wdrop (float): dropout used for a LSTM's internal (or hidden) recurrent weights.\n",
    "#dropoute (float): dropout to apply to the embedding layer.\n",
    "#dropouth (float): dropout to apply to the activations going from one LSTM layer to another\n",
    "kwargs = {'dropouti': drops[0], 'dropout': drops[1], 'wdrop': drops[2], 'dropoute': drops[3], 'dropouth': drops[4]}\n",
    "\n",
    "#returns a RNN_Learner with model ~ SequentialRNN(RNN_Encoder(...), LinearDecoder(...))\n",
    "learner = model_data.get_model(opt_fn = opt_fn, emb_sz = EMBEDDING_SIZE, n_hid = n_hid, n_layers = n_layers, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ModelData class needs to know training set, validation set (give data loaders for these) and optionally a test set, among others\n",
    "\n",
    "all the work happens in get_model(). - the key part - where we implement **AWD LSTM** and use the backbone+head 'big idea'\n",
    "\n",
    "    def get_model(self, opt_fn, emb_sz, n_hid, n_layers, **kwargs):\n",
    "            m = get_language_model(self.nt, emb_sz, n_hid, n_layers, self.pad_idx, **kwargs)\n",
    "\n",
    "We wrap this in a LanguageModel which defines layer groups - can have different lr for layer groups\n",
    "\n",
    "Then we turn into a RNN_Learner - Learner using cross entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Learner.unfreeze of SequentialRNN(\n",
       "  (0): RNN_Encoder(\n",
       "    (encoder): Embedding(9574, 400, padding_idx=1)\n",
       "    (encoder_with_dropout): EmbeddingDropout(\n",
       "      (embed): Embedding(9574, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDrop(\n",
       "        (module): LSTM(400, 1150, dropout=0.105)\n",
       "      )\n",
       "      (1): WeightDrop(\n",
       "        (module): LSTM(1150, 1150, dropout=0.105)\n",
       "      )\n",
       "      (2): WeightDrop(\n",
       "        (module): LSTM(1150, 400, dropout=0.105)\n",
       "      )\n",
       "    )\n",
       "    (dropouti): LockedDropout(\n",
       "    )\n",
       "    (dropouths): ModuleList(\n",
       "      (0): LockedDropout(\n",
       "      )\n",
       "      (1): LockedDropout(\n",
       "      )\n",
       "      (2): LockedDropout(\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=9574, bias=False)\n",
       "    (dropout): LockedDropout(\n",
       "    )\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.metrics = [accuracy]\n",
    "learner.unfreeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual we do a fit just on the last layer. The way this is setup the last layer is the embedding weights-which will be the thing that is most wrong.\n",
    "\n",
    "Train a single epoch of just the embedding weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-3\n",
    "lrs=lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy   \n",
      "    0      6.498056   6.177624   0.04674   \n",
      "\n",
      "elapsed: 13.984156095000799\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "learner.fit(lrs/2, 1, wds=wd, use_clr=(32,2), cycle_len=1)\n",
    "end = timer()\n",
    "print(f'elapsed: {end - start}')\n",
    "#showing seq_len and bptt values:\n",
    "# 0%|          | 0/6870 [00:00<?, ?it/s]initial seq_len: 95, bptt: 70\n",
    "# 0%|          | 1/6870 [00:01<2:29:15,  1.30s/it, loss=11]seq_len: 36, bptt: 70\n",
    "# 0%|          | 2/6870 [00:01<1:20:31,  1.42it/s, loss=11]seq_len: 73, bptt: 70\n",
    "# 0%|          | 3/6870 [00:01<1:00:29,  1.89it/s, loss=11]seq_len: 73, bptt: 70\n",
    "# 0%|          | 4/6870 [00:01<50:36,  2.26it/s, loss=11]  seq_len: 65, bptt: 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('lm_last_fit_mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load('lm_last_fit_mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy   \n",
      "    0      6.42268    6.250226   0.046847  \n",
      "\n",
      "elapsed: 13.364842133996717\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "learner.lr_find(start_lr=lrs/10, end_lr=lrs*10, linear=True)\n",
    "end = timer()\n",
    "print(f'elapsed: {end - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.sched.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start doing a few epochs of the full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy   \n",
      "    0      6.363764   6.188202   0.04686   \n",
      "    1      6.359659   6.19159    0.046905  \n",
      "    2      6.348705   6.186267   0.046874  \n",
      "    3      6.21878    5.886193   0.091488  \n",
      "    4      5.774761   5.490061   0.131883  \n",
      "    5      5.509296   5.303198   0.151286  \n",
      "    6      5.344964   5.196895   0.160693  \n",
      "    7      5.231449   5.114079   0.16873   \n",
      "    8      5.148436   5.055016   0.174045  \n",
      "    9      5.076343   5.012696   0.178602  \n",
      "    10     5.028503   4.975904   0.183761  \n",
      "    11     4.974692   4.961586   0.184975  \n",
      "    12     4.940303   4.931555   0.188118  \n",
      "    13     4.9065     4.915907   0.188738  \n",
      "    14     4.890351   4.907102   0.189275  \n",
      "\n",
      "elapsed: 207.95462071899965\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "learner.fit(lrs, 1, wds=wd, use_clr=(20,10), cycle_len=15)\n",
    "end = timer()\n",
    "print(f'elapsed: {end - start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loss compares with Lesson 4 - Academic worlds best in 2017 - aftewr 14 epochs val loss of 4.23. \n",
    "\n",
    "Here after 1 epoch on full model we have a 4.12 loss \n",
    "\n",
    "ie by pretraining on wikitext103 better loss after 1 epoch than best loss for Lesson 4 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for full dataset after 5 hrs (on GTX1080Ti):\n",
    "#14     4.045284   4.072163   0.299391  \n",
    "\n",
    "#1/50th dataset after 213 seconds (356 seconds on GTX1070):\n",
    "#14     4.899093   4.919841   0.187322  \n",
    "\n",
    "#1/100th dataset after 96 seconds:\n",
    "#14     5.937064   5.737786   0.097723  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('lm1_mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save_encoder('lm1_enc_mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.sched.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn = pd.read_csv(CLAS_PATH/'train_mini.csv', header=None, chunksize=CHUNKSIZE)\n",
    "df_val = pd.read_csv(CLAS_PATH/'test_mini.csv', header=None, chunksize=CHUNKSIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "elapsed: 3.3929726330025005\n"
     ]
    }
   ],
   "source": [
    "tok_trn, trn_labels = get_all(tf_reader=df_trn, n_lbls=1)\n",
    "tok_val, val_labels = get_all(tf_reader=df_trn, n_lbls=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "(CLAS_PATH/'tmp').mkdir(exist_ok=True)\n",
    "\n",
    "np.save(CLAS_PATH/'tmp'/'tok_trn_mini.npy', tok_trn)\n",
    "np.save(CLAS_PATH/'tmp'/'tok_val_mini.npy', tok_val)\n",
    "\n",
    "np.save(CLAS_PATH/'tmp'/'trn_labels_mini.npy', trn_labels)\n",
    "np.save(CLAS_PATH/'tmp'/'val_labels_mini.npy', val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_trn = np.load(CLAS_PATH/'tmp'/'tok_trn_mini.npy')\n",
    "tok_val = np.load(CLAS_PATH/'tmp'/'tok_val_mini.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9574"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos = pickle.load((LM_PATH/'tmp'/'itos_mini.pkl').open('rb'))\n",
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n",
    "len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_clas = np.array([[stoi[o] for o in p] for p in tok_trn])\n",
    "val_clas = np.array([[stoi[o] for o in p] for p in tok_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(CLAS_PATH/'tmp'/'trn_ids_mini.npy', trn_clas)\n",
    "np.save(CLAS_PATH/'tmp'/'val_ids_mini.npy', val_clas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_clas = np.load(CLAS_PATH/'tmp'/'trn_ids_mini.npy')\n",
    "val_clas =np.load(CLAS_PATH/'tmp'/'trn_ids_mini.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn_labels.shape: (1500, 1)\n",
      "squeezed trn_labels.shape: (1500,)\n"
     ]
    }
   ],
   "source": [
    "trn_labels = np.load(CLAS_PATH/'tmp'/'trn_labels_mini.npy')\n",
    "print(f'trn_labels.shape: {trn_labels.shape}')\n",
    "\n",
    "#Remove single-dimensional entries from the shape of an array.\n",
    "trn_labels = np.squeeze(trn_labels)\n",
    "print(f'squeezed trn_labels.shape: {trn_labels.shape}')\n",
    "val_labels = np.squeeze(np.load(CLAS_PATH/'tmp'/'val_labels_mini.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt =70\n",
    "em_sz = 400\n",
    "#number of hidden activation per LSTM layer\n",
    "n_hid= 1150\n",
    "#number of LSTM layers to use in the architecture\n",
    "n_layers = 3\n",
    "vocab_size = len(itos)\n",
    "bs = 48\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lbl = trn_labels.min()\n",
    "trn_labels -= min_lbl\n",
    "val_labels -= min_lbl\n",
    "n_class = int(trn_labels.max()) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds = TextDataset(trn_clas, trn_labels)\n",
    "val_ds = TextDataset(val_clas, val_labels)\n",
    "#extends torch Sampler, appears to do some sorting then randomize batches\n",
    "trn_samp = SortishSampler(trn_clas, key=lambda x: len(trn_clas[x]), bs=bs//2)\n",
    "#note sure is was but in lesson .pynb of if library changed, added bs here\n",
    "val_samp = SortishSampler(val_clas, key=lambda x: len(trn_clas[x]), bs=bs//2)\n",
    "trn_dl = DataLoader(trn_ds, bs//2, transpose=True, num_workers=1, pad_idx=1, sampler=trn_samp)\n",
    "val_dl = DataLoader(val_ds, bs, transpose=True, num_workers=1, pad_idx=1, sampler=val_samp)\n",
    "model_data = ModelData(PATH, trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#part 1\n",
    "dps = np.array([0.4, 0.5, 0.05, 0.3, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dps = np.array([0.4, 0.5, 0.05, 0.3, 0.4])*0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "get_rnn_classifer() returns SequentialRNN(MultiBatchRNN(RNN_Encoder), PoolingLinearClassifier(layers, drops))\n",
    "\n",
    "where RNN_Encoder modelled after **Merity et al (2017)**\n",
    "\n",
    "\"In this work, we investigate a set of regularization strategies that are not only highly effective butwhich can also be used with no modification to existing LSTM implementations. The weight-dropped LSTM applies recurrent regulariza- tion through a DropConnectmask on the hidden-to-hidden recurrent weights. Other strategies include the use of randomized-length backpropagation through time (BPTT), embedding dropout, activation regularization (AR), and temporal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq = 20*70\n",
    "layers=[em_sz*3, 50, n_class]\n",
    "drops=[dps[4], 0.1]\n",
    "\n",
    "#get_rnn_classifer(bptt, max_seq, n_class, n_tok, emb_sz, n_hid, n_layers, pad_token, layers, drops, bidir=False,\n",
    "#     dropouth=0.3, dropouti=0.5, dropoute=0.1, wdrop=0.5):\n",
    "m = get_rnn_classifer(bptt, max_seq, n_class=n_class, n_tok=vocab_size, emb_sz=em_sz, n_hid=n_hid, \n",
    "                      n_layers=n_layers, pad_token=1, layers=layers, drops=drops, dropouti=dps[0], \n",
    "                      wdrop=dps[1], dropoute=dps[2], dropouth=dps[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#why are we changing the optimizer?\n",
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learning using cross entropy criterion\n",
    "learn = RNN_Learner(model_data, TextModel(to_gpu(m)), opt_fn=opt_fn)\n",
    "#seq2seq_reg  regularization, if alphs then mult by a squared fn, beta is temporal activation regularization (slowness)\n",
    "learn.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "learn.clip=25.0\n",
    "learn.metrics = [accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "lrm = 2.6\n",
    "#discriminative weigth decay\n",
    "#lrs = np.array([lr/(lrm**4), lr/(lrm**3), lr/(lrm**2), lr/lrm, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs=np.array([1e-4,1e-4,1e-4,1e-3,1e-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying out weight decay\n",
    "#wd = 1e-7\n",
    "#wd = 0\n",
    "#learn.load_encoder('lm2_enc_mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                       \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 173 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-9b045eb09223>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msched\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/963GB/Data/Python/Courses/fastai/my_fastai/dl2/fastai/learner.py\u001b[0m in \u001b[0;36mlr_find\u001b[0;34m(self, start_lr, end_lr, wds, linear)\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mlayer_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLR_Finder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrn_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tmp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/963GB/Data/Python/Courses/fastai/my_fastai/dl2/fastai/learner.py\u001b[0m in \u001b[0;36mfit_gen\u001b[0;34m(self, model, data, layer_opt, n_cycle, cycle_len, cycle_mult, cycle_save_name, best_save_name, use_clr, use_clr_beta, metrics, callbacks, use_wd_sched, norm_wds, wds_sched_mult, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum_geom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcycle_len\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcycle_len\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle_mult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         return fit(model, data, n_epoch, layer_opt.opt, self.crit,\n\u001b[0;32m--> 198\u001b[0;31m             metrics=metrics, callbacks=callbacks, reg_fn=self.reg_fn, clip=self.clip, **kwargs)\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/963GB/Data/Python/Courses/fastai/my_fastai/dl2/fastai/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, data, epochs, opt, crit, metrics, callbacks, stepper, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstepper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mprint_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdebias_loss\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/963GB/Data/Python/Courses/fastai/my_fastai/dl2/fastai/model.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(stepper, dl, metrics)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0mbatch_cnts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0mstepper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstepper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mbatch_cnts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/963GB/Data/Python/Courses/fastai/my_fastai/dl2/fastai/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;31m# avoid py3.6 issue where queue is infinite and can result in memory exhaustion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_sampler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    584\u001b[0m                     \u001b[0;31m# Careful not to keep a reference to the popped future\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                         \u001b[0;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/963GB/Data/Python/Courses/fastai/my_fastai/dl2/fastai/dataloader.py\u001b[0m in \u001b[0;36mget_batch\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_y\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/963GB/Data/Python/Courses/fastai/my_fastai/dl2/fastai/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_y\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/963GB/Data/Python/Courses/fastai/my_fastai/dl2/fastai/text.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meos\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msos\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 173 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "learn.lr_find(lrs/1000)\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs, 1, wds=wd, cycle_len=1, use_clr=(8,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('clas_0_mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('clas_0_mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.feeze_to(-2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "learn.fit(lrs, 1, wds=wd, cycle_len=1, use_clr=(8,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('clas_1_mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('clas_1_mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs, 1, wds=wd, cycle_len=14, use_clr=(32,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('clas_2_mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
