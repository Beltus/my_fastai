{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used https://github.com/binga/fastai_notes/tree/master/experiments/notebooks/lang_models and https://github.com/sgugger/Deep-Learning/blob/master/Building%20a%20French%20LM.ipynb as starting points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS = 'xbos'  # beginning-of-sentence tag\n",
    "FLD = 'xfld'  # data field tag\n",
    "\n",
    "PATH=Path('..')/'data/lm/wikimedia/french/french_wiki/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LM_PATH=Path('..')/'data/lm/models/french/'\n",
    "LM_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standarize format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG_FILENAMES = [str(f) for f in PATH.rglob(\"*/*\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3928,\n",
       " ['../data/lm/wikimedia/french/french_wiki/AI/wiki_08',\n",
       "  '../data/lm/wikimedia/french/french_wiki/AI/wiki_65',\n",
       "  '../data/lm/wikimedia/french/french_wiki/AI/wiki_52',\n",
       "  '../data/lm/wikimedia/french/french_wiki/AI/wiki_69',\n",
       "  '../data/lm/wikimedia/french/french_wiki/AI/wiki_40'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(LANG_FILENAMES), LANG_FILENAMES[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3928/3928 [00:28<00:00, 138.87it/s]\n"
     ]
    }
   ],
   "source": [
    "LANG_TEXT = []\n",
    "for fn in tqdm(LANG_FILENAMES):\n",
    "    for line in open(fn, encoding='utf8'):\n",
    "        LANG_TEXT.append(json.loads(line))\n",
    "        \n",
    "LANG_TEXT = pd.DataFrame(LANG_TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>417579</td>\n",
       "      <td>Élisabeth Woodville\\n\\nÉlisabeth Woodville (au...</td>\n",
       "      <td>Élisabeth Woodville</td>\n",
       "      <td>https://fr.wikipedia.org/wiki?curid=417579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>417601</td>\n",
       "      <td>Macrocystis pyrifera\\n\\nMacrocystis pyrifera e...</td>\n",
       "      <td>Macrocystis pyrifera</td>\n",
       "      <td>https://fr.wikipedia.org/wiki?curid=417601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>417602</td>\n",
       "      <td>Goémon\\n\\nLe goémon (orthographié aussi goëmon...</td>\n",
       "      <td>Goémon</td>\n",
       "      <td>https://fr.wikipedia.org/wiki?curid=417602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>417611</td>\n",
       "      <td>Grímsey\\n\\nGrímsey est une petite île islandai...</td>\n",
       "      <td>Grímsey</td>\n",
       "      <td>https://fr.wikipedia.org/wiki?curid=417611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>417614</td>\n",
       "      <td>Circassie\\n\\nLa Circassie est une région histo...</td>\n",
       "      <td>Circassie</td>\n",
       "      <td>https://fr.wikipedia.org/wiki?curid=417614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text  \\\n",
       "0  417579  Élisabeth Woodville\\n\\nÉlisabeth Woodville (au...   \n",
       "1  417601  Macrocystis pyrifera\\n\\nMacrocystis pyrifera e...   \n",
       "2  417602  Goémon\\n\\nLe goémon (orthographié aussi goëmon...   \n",
       "3  417611  Grímsey\\n\\nGrímsey est une petite île islandai...   \n",
       "4  417614  Circassie\\n\\nLa Circassie est une région histo...   \n",
       "\n",
       "                  title                                         url  \n",
       "0   Élisabeth Woodville  https://fr.wikipedia.org/wiki?curid=417579  \n",
       "1  Macrocystis pyrifera  https://fr.wikipedia.org/wiki?curid=417601  \n",
       "2                Goémon  https://fr.wikipedia.org/wiki?curid=417602  \n",
       "3               Grímsey  https://fr.wikipedia.org/wiki?curid=417611  \n",
       "4             Circassie  https://fr.wikipedia.org/wiki?curid=417614  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LANG_TEXT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG_TEXT.to_csv(PATH/'wiki_fr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting rid of the title name in the text field\n",
    "def split_title_from_text(text):\n",
    "    words = text.split(\"\\n\\n\")\n",
    "    if len(words) >= 2:\n",
    "        return ''.join(words[1:])\n",
    "    else:\n",
    "        return ''.join(words)\n",
    "    \n",
    "LANG_TEXT['text'] = LANG_TEXT['text'].apply(lambda x: split_title_from_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>417579</td>\n",
       "      <td>Élisabeth Woodville (aussi écrit Wydville, Wyd...</td>\n",
       "      <td>Élisabeth Woodville</td>\n",
       "      <td>https://fr.wikipedia.org/wiki?curid=417579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>417601</td>\n",
       "      <td>Macrocystis pyrifera est une espèce d'algues b...</td>\n",
       "      <td>Macrocystis pyrifera</td>\n",
       "      <td>https://fr.wikipedia.org/wiki?curid=417601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>417602</td>\n",
       "      <td>Le goémon (orthographié aussi goëmon) ou herbe...</td>\n",
       "      <td>Goémon</td>\n",
       "      <td>https://fr.wikipedia.org/wiki?curid=417602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>417611</td>\n",
       "      <td>Grímsey est une petite île islandaise située à...</td>\n",
       "      <td>Grímsey</td>\n",
       "      <td>https://fr.wikipedia.org/wiki?curid=417611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>417614</td>\n",
       "      <td>La Circassie est une région historique située ...</td>\n",
       "      <td>Circassie</td>\n",
       "      <td>https://fr.wikipedia.org/wiki?curid=417614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text  \\\n",
       "0  417579  Élisabeth Woodville (aussi écrit Wydville, Wyd...   \n",
       "1  417601  Macrocystis pyrifera est une espèce d'algues b...   \n",
       "2  417602  Le goémon (orthographié aussi goëmon) ou herbe...   \n",
       "3  417611  Grímsey est une petite île islandaise située à...   \n",
       "4  417614  La Circassie est une région historique située ...   \n",
       "\n",
       "                  title                                         url  \n",
       "0   Élisabeth Woodville  https://fr.wikipedia.org/wiki?curid=417579  \n",
       "1  Macrocystis pyrifera  https://fr.wikipedia.org/wiki?curid=417601  \n",
       "2                Goémon  https://fr.wikipedia.org/wiki?curid=417602  \n",
       "3               Grímsey  https://fr.wikipedia.org/wiki?curid=417611  \n",
       "4             Circassie  https://fr.wikipedia.org/wiki?curid=417614  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LANG_TEXT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG_TEXT.to_csv(PATH/'wiki_fr1.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting the articles by length and keeping the first million."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG_TEXT = pd.read_csv(PATH/'wiki_fr1.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG_TEXT = LANG_TEXT.assign(length = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG_TEXT.columns = ['id', 'text', 'title', 'url', 'length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG_TEXT = LANG_TEXT.assign(labels = 0).pipe(lambda x: x[['labels', 'text', 'length']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG_TEXT['length'] = LANG_TEXT['text'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Élisabeth Woodville (aussi écrit Wydville, Wyd...</td>\n",
       "      <td>17833.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Macrocystis pyrifera est une espèce d'algues b...</td>\n",
       "      <td>3830.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Le goémon (orthographié aussi goëmon) ou herbe...</td>\n",
       "      <td>712.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Grímsey est une petite île islandaise située à...</td>\n",
       "      <td>986.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>La Circassie est une région historique située ...</td>\n",
       "      <td>1663.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                               text   length\n",
       "0       0  Élisabeth Woodville (aussi écrit Wydville, Wyd...  17833.0\n",
       "1       0  Macrocystis pyrifera est une espèce d'algues b...   3830.0\n",
       "2       0  Le goémon (orthographié aussi goëmon) ou herbe...    712.0\n",
       "3       0  Grímsey est une petite île islandaise située à...    986.0\n",
       "4       0  La Circassie est une région historique située ...   1663.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LANG_TEXT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG_TEXT = LANG_TEXT.sort_values(by=['length'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG_TEXT.to_csv(PATH/'wiki_fr1.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG_TEXT = LANG_TEXT[LANG_TEXT['length'] > 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"A note to those folks building langage models: there's no reason to go beyond 100 million tokens\" JH http://forums.fast.ai/t/language-model-zoo-gorilla/14623/17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG_TEXT = LANG_TEXT.iloc[0:1000000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting 10% for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_texts,val_texts = sklearn.model_selection.train_test_split(LANG_TEXT.pipe(lambda x: x[['labels', 'text']]), test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_texts.to_csv(PATH/'train.csv', header=False, index=False)\n",
    "val_texts.to_csv(PATH/'valid.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language model tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "re1 = re.compile(r'  +')\n",
    "\n",
    "def fixup(x):\n",
    "    x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>','u_n').replace(' @.@ ','.').replace(\n",
    "        ' @-@ ','-').replace('\\\\', ' \\\\ ')\n",
    "    return re1.sub(' ', html.unescape(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_texts(df, n_lbls=1):\n",
    "    labels = df.iloc[:,range(n_lbls)].values.astype(np.int64)\n",
    "    texts = f'\\n{BOS} {FLD} 1 ' + df[n_lbls].astype(str)\n",
    "    for i in range(n_lbls+1, len(df.columns)): texts += f' {FLD} {i-n_lbls} ' + df[i].astype(str)\n",
    "    texts = texts.apply(fixup).values.astype(str)\n",
    "    tok = Tokenizer.proc_all_mp(partition_by_cores(texts), lang='fr')\n",
    "    return tok, list(labels)\n",
    "\n",
    "def get_all(df, name, n_lbls=1):\n",
    "    for i, r in enumerate(df):\n",
    "        print(i)\n",
    "        tok_, labels_ = get_texts(r, n_lbls)\n",
    "        #optionally save the partial tokens instead of regrouping them in one big array.\n",
    "        np.save(PATH/f'{name}_tok{i}.npy', tok_)\n",
    "        #tok += tok_;\n",
    "        #labels += labels_\n",
    "    return tok, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn = pd.read_csv(PATH/'train.csv', header=None, chunksize=chunksize)\n",
    "df_val = pd.read_csv(PATH/'valid.csv', header=None, chunksize=chunksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n"
     ]
    }
   ],
   "source": [
    "get_all(df_trn,'trn',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all(df_val,'val',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_them_all(names):\n",
    "    cnt = Counter()\n",
    "    for name in names:\n",
    "        for file in PATH.glob(f'tmp/{name}_tok*'):\n",
    "            tok = np.load(file)\n",
    "            cnt_tok = Counter(word for sent in tok for word in sent)\n",
    "            cnt += cnt_tok\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = count_them_all(['trn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab = 60000\n",
    "min_freq = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = [o for o,c in cnt.most_common(max_vocab) if c > min_freq]\n",
    "itos.insert(0,'_pad_')\n",
    "itos.insert(0,'_unk_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = collections.defaultdict(int,{s:i for (i,s) in enumerate(itos)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numericalize each partial file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalize(name):\n",
    "    results = []\n",
    "    for file in tqdm(PATH.glob(f'tmp/{name}_tok*')):\n",
    "        tok = np.load(file)\n",
    "        results.append(np.array([[stoi[word] for word in sent] for sent in tok]))\n",
    "    return np.concatenate(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ids = numericalize('trn')\n",
    "np.save(PATH/'tmp/trn_ids.npy', trn_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ids = numericalize('val')\n",
    "np.save(PATH/'tmp/trn_ids.npy', val_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(itos, open(LM_PATH/'tmp'/'itos.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
